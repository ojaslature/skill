{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.info(),\n",
    "        data.describe(),\n",
    "        data.shape,\n",
    "        data.size,\n",
    "        data.head()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NAN\")\n",
    "nan_counts = data.isna().sum()\n",
    "print(nan_counts[nan_counts > 0])\n",
    "\n",
    "print(\"\\nNULL\")\n",
    "null_counts = data.isnull().sum()\n",
    "print(null_counts[null_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def scalling(data):\n",
    "    numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(numeric_data)\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=numeric_data.columns)\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalled_data=scalling(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.iloc[:,:-1]\n",
    "y=data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalled_x=scalled_data.iloc[:,:-1]\n",
    "scalled_y=scalled_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Method\n",
    "- it considers each feature independently\n",
    "- less computationally expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance Threshold\n",
    "- removes feature with low variance \n",
    "- assumes that high variance = more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "def varience(data):\n",
    "\n",
    "    numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
    "    selector = VarianceThreshold(threshold=0.2)\n",
    "\n",
    "    selected_data = selector.fit_transform(data)\n",
    "\n",
    "    selected_features = numeric_data.columns[selector.get_support()]\n",
    "\n",
    "    features_removed = [col for col in numeric_data.columns if col not in selected_features]\n",
    "\n",
    "\n",
    "    print(f\"Original features: {numeric_data.shape[1]}\")\n",
    "    print(f\"Features after variance thresholding: {selected_data.shape[1]}\")\n",
    "    print(f\"Features removed: {numeric_data.shape[1] - selected_data.shape[1]}\")\n",
    "    print(\"\\nSelected features:\")\n",
    "    print(selected_features.tolist())\n",
    "    print(\"\\nremoved features:\")\n",
    "    print(features_removed)\n",
    "    final_data = data[selected_features]\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled=scalling(data)\n",
    "varience(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correaltion-based selection\n",
    "- removes hig corr features as tehy likely provide redundant info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(data):\n",
    "    numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
    "    \n",
    "    corr_matrix = pd.DataFrame(numeric_data).corr().abs()\n",
    "\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "    print(to_drop)\n",
    "    data_selected = pd.DataFrame(data).drop(to_drop, axis=1)\n",
    "\n",
    "    return data_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Tests\n",
    "- Uses statistical tests to select features that have the strongest relationship with the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def chi2test(data):\n",
    "    x=data.iloc[:,:-1]\n",
    "    y=data.iloc[:,-1]\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "    columns_selected= chi2(xtrain,ytrain)\n",
    "    p_values=pd.Series(columns_selected[1])\n",
    "    p_values.index=xtrain.columns\n",
    "    return p_values.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "def anovatest(data):\n",
    "    x=data.iloc[:,:-1]\n",
    "    y=data.iloc[:,-1]\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "    selector = SelectKBest(f_classif, k=10)\n",
    "    X_selected = selector.fit_transform(xtrain, ytrain)\n",
    "\n",
    "    f_scores = selector.scores_\n",
    "    p_values = selector.pvalues_\n",
    "\n",
    "    feature_scores = pd.DataFrame({\n",
    "    \t'Feature': xtrain.columns,\n",
    "    \t'F Score': f_scores,\n",
    "    \t'P Value': p_values\n",
    "    })\n",
    "\n",
    "    feature_scores = feature_scores.sort_values('F Score', ascending=False)\n",
    "    print(feature_scores.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anovatest(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "def mutualinfotest(data):\n",
    "\tx=data.iloc[:,:-1]\n",
    "\ty=data.iloc[:,-1]\n",
    "\txtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "\tselector = SelectKBest(mutual_info_classif, k=10)\n",
    "\tX_selected = selector.fit_transform(xtrain, ytrain)\n",
    "\n",
    "\tf_scores = selector.scores_\n",
    "\n",
    "\tfeature_scores = pd.DataFrame({\n",
    "\t    'Feature': xtrain.columns,\n",
    "\t    'F Score': f_scores,\n",
    "\t})\n",
    "\n",
    "\tfeature_scores = feature_scores.sort_values('F Score', ascending=False)\n",
    "\tprint(feature_scores.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualinfotest(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper Method\n",
    "- use a predictive model to score feature subsets\n",
    "- train a new model on each feature subset and measure its performance to select the best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination (RFE)\n",
    "- Recursively removes the weakest feature(s) until the desired number of features is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def reftest(scalled_x,y):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "\n",
    "    selector = RFE(estimator=model, n_features_to_select=10, step=1)\n",
    "    X_selected = selector.fit_transform(scalled_x,y)\n",
    "\n",
    "    selected_features = scalled_x.columns[selector.support_]\n",
    "    print(\"Selected features:\", selected_features.tolist())\n",
    "\n",
    "\n",
    "    feature_ranking = pd.DataFrame({\n",
    "        'Feature': scalled_x.columns,\n",
    "        'Ranking': selector.ranking_\n",
    "    })\n",
    "    feature_ranking = feature_ranking.sort_values('Ranking')\n",
    "    print(\"\\nFeature ranking (1 = selected, higher = eliminated earlier):\")\n",
    "    print(feature_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reftest(scalled_x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward/Backward Selection\n",
    "- Forward selection starts with no features and adds them one by one, while backward selection starts with all features and removes them one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2025-03-20 23:42:29] Features: 1/10 -- score: 0.18991694170523726\n",
      "[2025-03-20 23:42:29] Features: 2/10 -- score: 0.3202729761019654\n",
      "[2025-03-20 23:42:30] Features: 3/10 -- score: 0.37901379189669787\n",
      "[2025-03-20 23:42:30] Features: 4/10 -- score: 0.4231779108022288\n",
      "[2025-03-20 23:42:30] Features: 5/10 -- score: 0.4541934600545228\n",
      "[2025-03-20 23:42:30] Features: 6/10 -- score: 0.47210549907312005\n",
      "[2025-03-20 23:42:30] Features: 7/10 -- score: 0.4879756394058109\n",
      "[2025-03-20 23:42:30] Features: 8/10 -- score: 0.4932556597799903\n",
      "[2025-03-20 23:42:30] Features: 9/10 -- score: 0.49719930134170864\n",
      "[2025-03-20 23:42:30] Features: 10/10 -- score: 0.4998121001307898\n",
      "[2025-03-20 23:42:30] Features: 12/10 -- score: 0.5003891746727683\n",
      "[2025-03-20 23:42:30] Features: 11/10 -- score: 0.5004238310924107\n",
      "[2025-03-20 23:42:30] Features: 10/10 -- score: 0.4998121001307898"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Forward selection\n",
    "sfs_forward = SFS(LinearRegression(), \n",
    "                  k_features=10, \n",
    "                  forward=True, \n",
    "                  verbose=2,\n",
    "                  scoring='r2')\n",
    "sfs_forward.fit(scalled_x, y)\n",
    "X_selected = sfs_forward.transform(scalled_x)\n",
    "\n",
    "# Backward selection\n",
    "sfs_backward = SFS(LinearRegression(), \n",
    "                   k_features=10, \n",
    "                   forward=False, \n",
    "                   verbose=2,\n",
    "                   scoring='r2')\n",
    "sfs_backward.fit(scalled_x, y)\n",
    "X_selected = sfs_backward.transform(scalled_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
